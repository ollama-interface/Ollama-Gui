# Ollama Chat App ğŸ V2

[![Build and Deploy](https://github.com/ollama-interface/Ollama-Gui/actions/workflows/build-and-deploy.yml/badge.svg?branch=main)](https://github.com/ollama-interface/Ollama-Gui/actions/workflows/build-and-deploy.yml)

Welcome to my Ollama Chat, this is an interface for the Official ollama CLI to make it easier to chat. It includes features such as:

- Multiple conversations ğŸ’¬
- Detect which models are available to use ğŸ“‹
- Auto-check if ollama is running â°
- Able to change the address where ollama is running ğŸ–¥ï¸
- Persistance ğŸ“€
- Import & Export Chats ğŸš›
- Light & Dark Theme ğŸŒ—

This is a re write of the first version of Ollama chat, The new update will include some time saving features and make it more stable and available for Macos and Windows. Also a new freshly look will be included as well.
<br />

Stay in touch for upcoming updates

<br />

Todo list:

- Add server auto start
- Add dark mode
- fix some minor bugs
- Improve settings page

Your machine needs to be set up to build Tauri apps. Follow the [Getting Started](https://tauri.app/v1/guides/getting-started/prerequisites) guide to ensure you system is set up correctly.

<br />
<br />

Welcome to my Ollama Chat, this is an interface for the Official ollama CLI to make it easier to chat. It includes futures such as:

- Improved interface design & user friendly
- ~~Auto check if ollama is running~~ _(**NEW**, Auto start ollama server)_ â°
- Multiple conversations ğŸ’¬
- Detect which models are available to use ğŸ“‹
- Able to change the host where ollama is running at ğŸ–¥ï¸
- Perstistance ğŸ“€
- Import & Export Chats ğŸš›
- Light & Dark Theme ğŸŒ—

For any questions, please contact [Twan Luttik (Twitter - X)](https://twitter.com/twanluttik)
